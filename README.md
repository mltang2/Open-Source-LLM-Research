# Open-Source-LLM-Research
With professor Dr. George Thomas, we spent the summer diving deep into how we can access open source large language models, fine tune them, and integrate them into existing applications. Here is what we found!

While it was possible to have applications access the interface programatically, it was easiest to incorporate applications that already had functionalities that could download and run different llms efficiently. After playing around with multiple platforms including like UnionCloud, TensorFlow, and Ollama, we ultimately decided to continue with Ollama. The main reason for this choice was because of the ease of use that Ollama provided. With its potential for local execution with hundreds of open source models, mixed in with its endless possibilities for customization, versatility, and integration, Ollama was the best platform to run large language models. 


